## 深入了解机器学习

**线性回归**是一种找到最合适一组点的直线或超平面的方法

### 线性回归
对于简单的关系，可以通过xy轴的线性关系来进行表示，将点标记在xy图表中，绘制一条直线来近似地表示这种关系。虽然该直线并未精确无误地经过每个点，但针对拥有的数据，清楚的显示了x和y之间的关系。
得出关系表达式：

```
y = mx + b
```

其中：
`m`指直线的斜率
`b`指y轴截距

按照机器学习的管理，需要写一个存在细微差别的模型方程式：

```
y' = b + w1x1
```
其中：
`y'`指预测标签（理想输出值）
`b` 指的是偏差（y轴的截距）。在一些文档中，称为w0
`w1`指特征1的权重。权重与👆中用`m`表示的“斜率”的概念相同
`x1`指特征（已知输入项）

然后就可以根据已知的`x1`来进行预测对应的`y'`

可以用多个特征来表示更复杂的模型：
```
y' = b + w1x1 + w2x2 + w3x3
```


### 定义数据集上的L2损失
对训练集中所有样本损失平方进行求和

### 训练与损失
**训练**模型表示通过标签样本来学习（确定）所有权重和偏差的理想值。

在监督学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试出最大限度地减少损失的模型；这个过程称为**经验风险最小化**

**损失**是一个数值，表示对于单个原本而言模型预测的准确程度。
训练模型的目标是从所有样本中找到一组平均损失“较小”的权重和偏差。

#### 平方损失 ： 一种常见的损失函数
给定样本的L2损失（平方误差）
= 预测值和标签值之差的平法
= （观察值 - 预测值）2
= （y - y'）2

**均方误差（MSE）**指每个样本的平均平方损失。
求出各个样本的所有平方损失之和，然后除以样本数量：

